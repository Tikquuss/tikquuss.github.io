I"à
<div class="list__item">
  <article class="archive__item" itemscope="" itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/publication/2023-06-23-paper-at" rel="permalink">Predicting Grokking Long Before it Happens: A look into the loss landscape of models which grok
</a>
      
    </h2>
    
    

        
          <!--- <p>Published in <i>preprint</i>, 2023 </p> --->
          <p><i>preprint</i>, 2023 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description">
</p>
    
    
    
      <p>Download <a href=" https://arxiv.org/abs/2306.13253 "><u>here</u></a></p>
    

  </article>
</div>

<div class="list__item">
  <article class="archive__item" itemscope="" itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/publication/2022-02-02-paper-at" rel="permalink">Adaptive Discrete Communication Bottlenecks with Dynamic Vector Quantization for Heterogeneous Representational Coarseness
</a>
      
    </h2>
    
    

        
          <!--- <p>Published in <i>Dianbo Liu, Alex Lamb, Xu Ji, Pascal Jr. Tikeng Notsawo, Mike Mozer, Yoshua Bengio, Kenji Kawaguchi, AAAI</i>, 2023 </p> --->
          <p><i>Dianbo Liu, Alex Lamb, Xu Ji, Pascal Jr. Tikeng Notsawo, Mike Mozer, Yoshua Bengio, Kenji Kawaguchi, AAAI</i>, 2023 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>Vector Quantization (VQ) is a method for discretizing latent representations and has become a major part of the deep learning toolkit. It has been theoretically and empirically shown that discretization of representations leads to improved generalization, including in reinforcement learning where discretization can be used to bottleneck multi-agent communication to promote agent specialization and robustness. The discretization tightness of most VQ-based methods is defined by the number of discrete codes in the representation vector and the codebook size, which are fixed as hyperparameters. In this work, we propose learning to dynamically select discretization tightness conditioned on inputs, based on the hypothesis that data naturally contains variations in complexity that call for different levels of representational coarseness which is observed in many heterogeneous data sets. We show that dynamically varying tightness in communication bottlenecks can improve model performance on visual reasoning and reinforcement learning tasks with heterogeneity in representations.</p>
</p>
    
    
    
      <p>Download <a href=" https://arxiv.org/pdf/2202.01334.pdf "><u>here</u></a></p>
    

  </article>
</div>

<div class="list__item">
  <article class="archive__item" itemscope="" itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/publication/2021-12-15-paper-at" rel="permalink">On the use of linguistic similarities to improve Neural Machine Translation for African Languages
</a>
      
    </h2>
    
    

        
          <!--- <p>Published in <i>5th Black in AI Workshop @ NeurIPS 2021</i>, 2021 </p> --->
          <p><i>5th Black in AI Workshop @ NeurIPS 2021</i>, 2021 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description">
</p>
    
    
    
      <p>Download <a href=" https://openreview.net/pdf?id=Q5ZxoD2LqcI "><u>here</u></a></p>
    

  </article>
</div>

:ET