---
title: "Predicting Grokking Long Before it Happens: A look into the loss landscape of models which grok"
collection: publications
permalink: /publication/2023-06-23-paper-at
#excerpt: 'This paper is about the number 1. The number 2 is left for future work.'
date: 2023-06-23
venue: 'preprint'
paperurl: 'https://arxiv.org/abs/2306.13253'
#citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
#citation : 'Pascal Jr. Tikeng Notsawo, Hattie Zhou, Mohammad Pezeshki, Irina Rish, Guillaume Dumas. (2023). "Predicting Grokking Long Before it Happens: A look into the loss landscape of models which grok." <i>preprint</i>.'
authors : Pascal Jr. Tikeng Notsawo, Hattie Zhou, Mohammad Pezeshki, Irina Rish, Guillaume Dumas
---
[comment]: <> This paper is about the number 1. The number 2 is left for future work.

This paper focuses on predicting the occurrence of grokking in neural networks, a phenomenon in which perfect generalization emerges long after signs of overfitting or memorization are observed. It has been reported that grokking can only be observed with certain hyper-parameters. This makes it critical to identify the parameters that lead to grokking. However, since grokking occurs after a large number of epochs, searching for the hyper-parameters that lead to it is time-consuming. In this paper, we propose a low-cost method to predict grokking without training for a large number of epochs. In essence, by studying the learning curve of the first few epochs, we show that one can predict whether grokking will occur later on. Specifically, if certain oscillations occur in the early epochs, one can expect grokking to occur if the model is trained for a much longer period of time. We propose using the spectral signature of a learning curve derived by applying the Fourier transform to quantify the amplitude of low-frequency components to detect the presence of such oscillations. We also present additional experiments aimed at explaining the cause of these oscillations and characterizing the loss landscape.

Paper : [arXiv.org:2306.13253[cs.LG]](https://arxiv.org/abs/2306.13253)